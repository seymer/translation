前言
===

过去20年互联网的快速增长改变了我们分享、收集和发布数据的方式。企业、政府机构和个人用户提供了各种能想象到的信息类型，新的沟通渠道也产生了大量有关人类行为的数据 。社会科学领域曾经的根本性问题 -- 观测数据的稀缺和难以获取 -- 正在快速扭转为数据取之不尽用之不竭的局面。这种翻天覆地的形势也并非尽善尽美。例如，传统的数据采集和分析技术可能不足以应对复杂的大量数据。 对这种大数据需求进行分析产生的结果之一是所谓“数据科学家”的诞生，他们能对数据进行筛选，在研究者和企业那里都很受欢迎。

随着互联网的高歌猛进，我们还见证了第二个趋势，那就是像 R 这样的开源软件越来越流行，越来越有影响力。对于计量社会科学家来说，R 是最重要的分析软件之一。它得益于有一个不断发布新组件的活跃社区，一直在快速地成长。到现在，R 已经不仅仅是一个免费统计软件包。它还包含了许多其他编程语言和软件包的接口，这样就大大简化了各种来源数据的处理工作。

从我们个人角度来说，我们可以总结出下列我们对社会科学数据所做的工作：

```
· 我们的资金是比较稀缺的； 
· 我们既没有时间也不愿意去手工采集数据； 
· 我们感兴趣的是利用最新、高质量和海量的数据来源；并且 
· 我们需要记录从开始（数据采集）到结束（发布结果）的整个研究过程，这样它就可以被重现。
```

在过去，我们经常困扰于对出自各种来源的数据进行手工整理，希望由此不可避免地带来的编程和拷贝-粘贴错误只是非系统性的。最终我们越来越厌倦那种不可重现的研究数据采集方式 ，这种方式易于出错、缓慢复杂，而且容易导致烦躁至死的风险升高。因此，我们不断地把数据采集和发布流程并入我们在统计分析过程中已熟悉的软件环境 -- R。这套程序提供了一套很好的基础架构，可以把每天的工作流程扩展为实际数据分析前后的一系列步骤。

虽然目前 R 本身还不是用来采集数据或进行实验的，我们还是认为本书讲述的技术不仅仅是对于成本高昂的调查、实验和学生助理编程者的“穷人的替代品”。 我们相信它们是现代数据分析工具组合的有力补充。我们推崇对在线资源的数据进行采集，不仅因为这样做的价值在于它相比传统的数据采集方法是更代价敏感的解决方案， 更将其视为从新的和不断开发中的数据源中整合数据集的特有方法。此外，我们重视基于电脑程序的解决方案，因为它们能确保可靠性、重现能力、时间效率以及高质量数据集的整合。 除了工作效率以外，你还会发现自己乐于通过写代码和设计算法方案替代乏味的手工劳动。简而言之，我们相信，如果你愿意花时间学习和采纳本书中推荐的技术， 在数据分析的简便性和质量上得到的持续提升定会让你受益匪浅。

假定你已经确定在线数据是你项目适用的资源，是否真的有必要采用网络抓取或统计文本处理技术，以及随之而来的自动化或半自动化数据采集流程？ 虽然我们不能指望拿出一锤定音的准则，但下面是一些有用的判断条件。如果你发现自己符合其中的好几个条件，那么自动化的方法可能就是你正确的选择：

```
· 你是否计划要经常重复这项任务？比如说需要通过它来保持数据库的更新。 
· 你是否需要让其他人能重复你的数据采集过程？ 
· 你是否经常要处理在线的数据源？ 
· 这项任务在规模和复杂度上是否非同小可？ 
· 如果这项任务也可以手工完成的话......你是否缺乏调动其他人参与所需的资源？ 
· 你是否愿意通过编程的手段实现自动化流程？
```

理想情况下，本书讲述的技术让你能够以相当合理的成本创建强大的数据集，这些数据集来自现有的、非结构化或未排序的数据，之前也没有人分析过它们。在很多情况下， 根据你的研究主题的特点，你需要对本书讲述的技术重新思考、提炼和组合，才能有所成效。在任何情况下，我们都希望你能发现本书的主题对你有所启发，能开阔你的眼界： 网络的街道是用数据铺成的，这些数据正迫不及待地等着被采集。


你不会从本书中学到的内容
---

当你浏览目录的时候，你会对阅读本书之后有望学到的东西有个第一印象。虽然我们很难确定有哪些部分是你希望有却不在本书范围内的， 我们还是会指出你在本书找不到的某几个方面的内容。

你在本书中不会看到对 R 环境的介绍。这方面已经有很多出色的介绍材料了 -- 不管是印刷版的还是在线的 -- 在本书里就不再赘述。如果你之前没有用过 R 的话，也大可不必失望地将此书束之高阁。下一节我们会推荐一些写得很好的 R 入门教材。

你也不要指望网络抓取或文本挖掘的完整讲解。首先，我们的重点是一套软件环境，而它并不是为实现这些目的而量身定制的。在一些应用需求下，R 对于你要完成的任务并非理想解决方案，其他软件包可能更合适。我们也不会用诸如PHP、Python、Ruby或Perl之类的替代环境来干扰你。 想知道本书是否对你有帮助，你应该扪心自问，是否已经或计划把 R 用在你的日常工作中。如果对这两个问题的答案都是否定的，很可能你应该考虑替代方案了。但是，如果你已经在用或倾向于使用 R 的话，你就可以省下学习另一个开发语言的精力，留在熟悉的开发环境里。

本书也不会严谨地介绍数据科学。在这个主题方面，也有一些出色的教材，例如最近O'Neil and Schutt(2013)， Torgo(2010)， Zhao(2012)，Zumel 和 Mount(2014) .......

`( 以上书名暂略 )`

出版的新书。在这些教材中偶尔缺失的部分是数据科学中用到的数据在真实环境中是如何获取的。在这方面，我们的教材就承担了数据分析的准备步骤， 而且也提供了关于如何管理可用信息并保持其同步的指导原则。

最后，你最不可能从本书看到的是针对你特定问题的完美解答。在数据采集过程中，获取数据的域从来都不会完全相似，而且有时其形式会快速变化，这都是固有的问题。 我们的目标是让你能改写例子和案例分析中提供的代码，创建新的代码，以此来帮助你在采集自己所需数据的工作中获得成功。



为什么用 R ？ 
---

对于本书中涵盖的问题，R 是一个很好的解决方案，我们这么考虑是有很多原因的。对我们来说，最重要的几点原因如下： 

1. R 可以自由和简便地获得。你可以按自己的需要随时随地下载、安装和使用它。不做那些昂贵的专有软件的专家对你是大有裨益的，因为你不需要依赖于雇主支付版权费的意愿。 

2. 作为一个主要专注于统计学的软件环境，R 拥有一个巨大而持续繁荣的社区。R 被用于各种专业领域，例如社会科学家、医学科学家、心理学家、生物学家、地理学家、语言学家以及商业企业等。这样的范围让你能与很多开发者共享代码， 并从文档完善的多领域应用中获益。 
 
3. R 是开源的。这意味着你能够轻松地分析函数的工作原理并毫不费力地修改它们。这也意味着对程序的修改不会被一个维护产品的独家程序员团队所控制。即使你无意向 R 的开发贡献代码，你仍然可以受益于能获取种类繁多的可选扩展项 -- 组件。组件的数量与日俱增，很多已有的组件也经常有更新。你能在这里找到关于使用 R 的流行主题不错的概述： http://cran.r-project.org/web/views/ 

```
步骤                           工具
---------------------------------------------------
研究问题，理论，设计              大脑
数据采集                        使用MS Excel手工进行
数据处理                        MS Excel
数据分析                        SPSS
发布                           MS Word，Endnote
---------------------------------------------------
图1 不使用 R 的研究过程  -- 程式化的例子
```

4. 对于常规任务 R 是相当快的。如果你用过类似于 SPSS 或 Stata 的其他统计软件，并养成了在计算较复杂模型的时候去度个假的习惯，你应该会赞同这个印象，更不用提那种由“一个会话，一套数据框架”的逻辑带来的切肤之痛了。 甚至还有一些扩展可以用来加速 R ，例如在 R 的内部使用 C 代码，类似 Rcpp 组件。

5. R 在构建数据可视化方面也很强大。虽然这对于数据采集并非显著的增值，在日常工作中你还是不会愿意错过 R 的图形特色。我们会演示被采集数据的视觉化检查能够且必须成为数据校验的第一步，以及图形可视化是如何提供一套直观的方式来总结海量数据的。

6. 使用 R 的工作主要是基于命令行的。这在 R 菜鸟听起来也许像是一个不足，但相比那些要用鼠标点击的程序来说，这是唯一能做到产生可重现结果的方式。

7. R 对于操作系统是不挑的。它通常可以在 Windows，Mac OS 和 Linux 下运行。

8. 最后， R 是能自始至终支持研究过程的完整软件包。如果你在读这本书，你应该不是专职程序员，而是对于你要从事的某个主题或特定数据源有相当大的兴趣。在那种情况下，学习另一门语言不会有成效， 反而会让你无法开展研究工作。普通研究流程的一个例子如图1所示。它的特点是永远在各种程序之间切换。如果你需要对数据采集过程进行修正，你就不得不顺着整个梯子爬回去。 而使用 R 的研究过程，正如在本书中所讲述的，只在单一的软件环境中进行（图2）。对于网络抓取和文本处理而言，这意味着你不必为这项任务去学习另一门编程语言。 你需要学习的只是一些标记语言 HTML 的基础知识， XML，正则表达式的逻辑和 XPath等，但所需的操作都是在 R 内部执行的。

```
步骤                           工具
---------------------------------------------------
研究问题，理论，设计              大脑 / R
数据采集                        R
数据处理                        R
数据分析                        R
发布                           LATEX / R
---------------------------------------------------
图2 使用 R 的研究过程  -- 程式化的例子
```

R 起步阶段的推荐读物
---

市面上有很多写得很好的介绍 R 的书。在它们当中，我们发现以下几本尤其有帮助： Crawley ...... Adler ...... Teetor ......

`以上书名暂略`

除了这些商业化的资源，网上还有很多免费的信息。对于绝对菜鸟来说，Code School 上有个真正超棒的在线教程，可以在 http://tryr.codeschool.com 看到。另外，Quick-R(http://www.statmethods.net/ ）里有很多基本命令的索引。最后，你也可以在 http://www.ats.ucla.edu/stat/r/ 找到很多免费资源和例子。

R 是一个不断成长中的软件，为了跟上它的进展，你也许会需要定期访问下面的网站：Planet R (http://planetr.stderr.org/ )， 它提供了已有组件的发布历史，偶尔还会介绍一些有意思的应用。R-Bloggers(http://www.r-bloggers.com/ )是个博客大杂烩，它专门收集有关 R 的各种领域的博客。它提供了针对数以百计的 R 应用的广阔视角，这些应用涉足的领域从经济学到生物学到地理学，大部分都附有重现博文内容所必需的代码。R-Bloggers 甚至推介了一些探讨自动化数据采集的例子。

当你遇到问题的时候，R 的帮助文件有时候不是特别有帮助。往往去Stack Overflow(http://stackoverflow.com/ ) 这样的在线论坛或 Stack Exchange 网络旗下的其他站点寻求帮助会更有启发。对于复杂问题，可以考虑去 GitHub（http://github.com/ ) 上找一些 R 的专家。另外请注意，还有很多特别兴趣小组（SIG)的邮件列表（http://www.r-project.org/mail.html/ ），里面划分了多种多样的主题， 甚至还有覆盖全世界的同城 R 用户小组（http://blog.revolutionanalytics.com/local-r-groups.html/ ）。最后，有人建了个 CRAN 任务视图，较好地概括了近期 web 技术的进展和 R 框架里的服务：http://cran.r-project.org/web/views/WebTechnologies.html）


本书版式的惯例 
---
本书是关于编程实践的，我们期望你经常把它放在键盘旁边的某个地方备用。我们会在整本书的讲解过程中遵循如下的惯例：书中有三套索引 -- 一套对应一般主题，一套对应 R 组件，还有一套对应 R 函数。在文本中，变量、 R 代码（也包括其他语言的代码）和函数都设为了打字机字体，例如 summary()。实际的 R 代码也是打字机字体，并有缩进。注意代码输入都用字母“R“加上提示符表示（“R>”）；R 程序输出的打印则是没有提示符的，例如： 

```
R> hello <- "hello, world" 
R> hello 
[1] "hello, world"
```

本书的网站 
---
与本书配套的网站可以在 http://www.r-datacollection.com/  找到。

该网站提供了书中例子和案例分析的相关代码，以及其他一些东西。这意味着你无须手工从书中复制代码，而是直接访问和修改相应的 R 文件即可。你也可以在里边找到某些练习题的解答，还有本书的勘误表。如果你在书中发现了任何错误，也请不吝告知。


免责声明
---
这不是一本关于网络抓取的书。网络蜘蛛是在互联网上抓取信息的程序，它能很快地从一个网页跳转到另一个网页，往往会抓取整个网页的内容。如果你想追随的是 Google 的 Googlebot 的足迹，那你很可能拿错书了。本书介绍的技术是用于更明确、更温柔的工作，也就是从特定的网站抓取特定的信息。最后，你要为自己学会这些技术后的所作所为负责哦。 从本书示例的代码到惹毛网站管理员的程序之间往往没有太大的鸿沟。所以，下面是一些关于如何做好一个网络数据采集从业者的重要忠告： 

1. 牢记你的数据是从何而来，在可能的时候，感谢那些最初采集并发布它的人们。 

2. 如果你打算二次发布那些在网络上找到的数据，切勿违反版权协议。如果这些信息不是你自己采集的，有时你会需要所有权人的许可才能对其进行加工。 

3. 不要做任何违法的事情！要了解你在数据采集过程中能做和不能做的事情，可以去 Justia BlawgSearch（http://blawgsearch.justia.com/ ，这是一个搜索法律相关博客的网站）核对一下。在里边搜索被标记为“web scraping（网络抓取）”的结果有助于你了解相关法律的进展和近期的判决。另外，电子前沿基金会（http://www.eff.org/ ）早在1990年就成立了， 它致力于保护消费者和大众的数字权利。不过，我们希望你永远不需要仰仗他们的帮助。

关于从网络抓取内容的行为，我们在 9.3.3 节提出了一些更详细的建议。


致谢
---
`暂略`
